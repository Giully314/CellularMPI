INTRODUZIONE

Questo programma presenta la computazione di un automa cellullare con l'utilizzo di MPI, per un sistema distribuito.
La scelta dell'automa e delle regole implementate sono personali, ma possono essere cambiate facilmente modificando
le funzioni adeguate. Prima di scrivere un programma che viene eseguito in parallelo (in questo caso su più 
calcolatori diversi) preferisco scrivere una prima bozza in seriale, per verificare la correttezza del programma 
e farmi un'idea su quali patterns utilizzare e come impostare l'architettura del programma. Partiamo parlando della
topologia che ho scelto.

Nota sul programma:
Si può scegliere quante righe assegnare ad ogni processo cambiando il paramentro ROWS_PER_PROC. Stessa cosa vale
per il numero di colonne. Il terminale, per stampare in modo corretto deve essere della dimensione adeguata ai 
parametri citati sopra.

comandi per compilare ed eseguire il programma:
mpicc parallel.c -fopenmp -o main
mpiexec -n num_of_proc ./main



TOPOLOGIA
La topologia che ho scelto è una topologia cartesiana ad anello, ad una dimensione (ovviamente non avendo l'hardware
per provare le varie configurazioni fisiche, questa scelta è prettamente personale). Se si utilizzassero regole più
complesse per descrivere gli automi cellulari in situazioni particolari, una topologia interessante da utilizzare
sarebbe quella a grafo. In questo modo si potrebbe pensare di scegliere una regola diversa per ogni calcolatore,
per simulare una popolazione diversa, e implementare delle regole apposite per vedere come si comportano le popolazioni
diverse a contatto con diverse altre popolazioni.



AUTOMA CELLULARE
Per quanto riguarda gli automi cellulari, ho preso principalmente spunto da un articolo di Wolfram contenuto nel suo 
libro "A new kind of science". Molto interessanti le 4 classi a cui può appertenere un'automa e che determina il suo
comportamento. Probabilmente farò degli esperimenti con le classi di automi che simulano i fluidi, appena finirò di 
costruire il mio mini cluster fatto di RaspberryPi.



COMUNICAZIONE
La comunicazione tra processi, in questo caso, è molto semplice. Ogni processo comunica con soli altri 2 processi:
quello alla sua "destra" e quello alla sua "sinistra". La comunicazione è non bloccante. Per quanto riguarda i costi,
la comunicazione è quella che costa di più in termini di tempo e risorse. E' essenziale che venga limitata il più
possibile. Ecco perchè, la mia prima versione parallela del programma, prevedeva l'inizializzazione indipendente 
delle risorse per ogni processo, con un solo processo che si occupava del Gather delle informazioni e della stampa.
In questo modo l'unica comunicazione era solo per la raccolta dati, e per lo scambio dei ghost points.



MULTITHREADING
Per mancanza di hardware (il programma è stato scritto utilizzando una macchina virtuale e ho un pc poco performante),
non ho potuto implementare una parallelizzazione adeguata a causa della mancanza di possibilità di testare il risultato
finale e vedere se le performance migliorassero. Ovviamento ho fatto i vari calcoli teorici, ma si fermano ad un livello
astratto ed è impossibile dedurne qualcosa facendo girare il programma su un solo core. L'unica parte che ho parallelizzato
è stata l'applicazione della regola. Questo perché ogni riga viene processata in modo indipendente e questo si traduce
in una possibile parallelizzazione del ciclo for. Avrei preferito utilizzare Cilkplus, che dispone di un sistema di 
load-balancing molto interessante (più informazioni a riguardo nel libro Structured parallel programming), a differenza
di OMP. Tra le altre cose, OMP soffre di una mancanza molto importante che è il supporto al nesting pattern 
(altre informazioni in Structured parallel programming ) in modo "automatico".




MISURAZIONE DELLE PERFORMANCE E GRAFICA
Per quanto riguarda la misurazione delle performance, ho avuto problemi nell'installare e utilizzare (poichè la 
librearia in questione è deprecata) MPE per il logging e la misura delle performance di applicazioni che usano MPI.
Ovviamente si può utilizzare MPI_WTime() per misurare le performance ma è un po' una scelta "primitiva" poiché 
bisognerebbe scrivere un'API per interfacciarsi in modo decente e pulito.
Stessa cosa vale per MPE graphics. 
Ho scelto quindi di implementare una semplice funzione che stampi l'array e imposti il colore e il carattere in base 
al valore della cellulla.




RISORSE

Automi
A new kind of science by S. Wolfram.
https://en.wikipedia.org/wiki/Cellular_automaton


Risorse per MPI e architettura parallela
https://pages.tacc.utexas.edu/~eijkhout/pcse/html/
https://pages.tacc.utexas.edu/~eijkhout/istc/html/index.html

Archiettura dei calcolatori by Tanenbaum & Austin

MPI: The Complete Reference  Marc Snir, Steve Otto, Steven Huss-Lederman, David Walker, Jack Dongarra.
Using MPI: Portable Parallel Programming With the Message-Passing Interface by Gropp, Lusk, Skjellum.

Structured parallel programming. Patterns for efficient computation by McCool, Robison, Reinders.

Articoli
Parallelisation Strategies for Large Scale Cellular Automata Frameworks in Pharmaceutical Modelling.
Scaling hybrid coarray/MPI miniapps on Archer.
Performance analysis of Cellular Automata HPC implementations.
